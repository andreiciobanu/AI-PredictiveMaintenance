{"cells":[{"cell_type":"markdown","source":["# Data Ingestor for IoT Telemetry and Failure Data\n","\n","This notebook ingests and preprocesses IoT device telemetry data in the Azure blob service and IoT device failure logs in Azure storage table to use in Feature Engineering and Model Training.\n","\n","This imitates a production scenario where telemetry is collected over a period of time whereas failure/maintenance logs are manually populated with new data.\n"],"metadata":{}},{"cell_type":"markdown","source":["### Dependency Importing and Environment Variable Retrieval"],"metadata":{}},{"cell_type":"code","source":["pip install azure-cosmosdb-table"],"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting azure-cosmosdb-table\n","  Downloading azure_cosmosdb_table-1.0.6-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 6.7 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: requests in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-cosmosdb-table) (2.24.0)\n","Requirement already satisfied: cryptography in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-cosmosdb-table) (3.0)\n","Requirement already satisfied: azure-common>=1.1.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-cosmosdb-table) (1.1.25)\n","Requirement already satisfied: python-dateutil in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-cosmosdb-table) (2.8.1)\n","Collecting azure-cosmosdb-nspkg>=2.0.0\n","  Downloading azure_cosmosdb_nspkg-2.0.2-py2.py3-none-any.whl (2.9 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->azure-cosmosdb-table) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->azure-cosmosdb-table) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->azure-cosmosdb-table) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->azure-cosmosdb-table) (1.25.10)\n","Requirement already satisfied: six>=1.4.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from cryptography->azure-cosmosdb-table) (1.15.0)\n","Requirement already satisfied: cffi!=1.11.3,>=1.8 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from cryptography->azure-cosmosdb-table) (1.14.1)\n","Requirement already satisfied: azure-nspkg>=2.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-cosmosdb-nspkg>=2.0.0->azure-cosmosdb-table) (3.0.2)\n","Requirement already satisfied: pycparser in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography->azure-cosmosdb-table) (2.20)\n","Installing collected packages: azure-cosmosdb-nspkg, azure-cosmosdb-table\n","Successfully installed azure-cosmosdb-nspkg-2.0.2 azure-cosmosdb-table-1.0.6\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"execution_count":9,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1598294566315}}},{"cell_type":"code","source":["import os\n","import string\n","import json\n","import pandas as pd\n","import pyspark.sql.functions as F\n","from pyspark.sql import SparkSession, SQLContext\n","from pyspark.sql.functions import udf\n","from pyspark.sql.types import TimestampType, StringType\n","from pyspark.storagelevel import StorageLevel\n","from azure.cosmosdb.table.tableservice import TableService"],"outputs":[],"execution_count":8,"metadata":{"gather":{"logged":1598301614400}}},{"cell_type":"markdown","source":["#### Read Environment Variables"],"metadata":{}},{"cell_type":"code","source":["STORAGE_ACCOUNT_SUFFIX = 'core.windows.net'\n","STORAGE_ACCOUNT_NAME = 'ws1237100807342'\n","STORAGE_ACCOUNT_KEY = 'lw3oUodMT+6sVFrHY02WgmcktJhH1YpbyHjU4zOmgpckFdtoWbJPWWkwyVi8MHbzMzdFDaHSJNrfoc1cOFyqJA=='\n","TELEMETRY_CONTAINER_NAME = 'azureml-blobstore-0ff7b38e-1ad8-4df4-ba02-5135c243b83f'\n","LOG_TABLE_NAME = 'logs'\n","\n","from pathlib import Path\n","DATA_ROOT = os.path.join(os.getcwd(), \"data\")"],"outputs":[],"execution_count":10,"metadata":{"gather":{"logged":1598301695728}}},{"cell_type":"markdown","source":["### Setting up Ingested Data Drop Folder\n","This location is where the prepared ingested IoT data is stored for further use in the notebooks to follow."],"metadata":{}},{"cell_type":"code","source":["data_dir = DATA_ROOT + '/data'\n","\n","#TODO: Convert data_dir into env variable\n","% rm -rf $data_dir\n","% mkdir $data_dir $data_dir/logs"],"outputs":[{"output_type":"stream","name":"stderr","text":["UsageError: Line magic function `%` not found.\n"]}],"execution_count":3,"metadata":{"gather":{"logged":1598301302730}}},{"cell_type":"markdown","source":["### Retrieving telemetry data\n","The raw data retrieved from the PdM solution storage contains all the IoT telemetry data in the \"Body\" column of the dataframe in a byte array. It needs to be deserialized into a string representing JSON, then expanded into a separate dataframe to be used by FeatureEngineering and ModelTraining."],"metadata":{}},{"cell_type":"code","source":["wasbTelemetryUrl = \"wasb://{0}@{1}.blob.{2}/*/*/*/*/*/*/*\".format(TELEMETRY_CONTAINER_NAME, \n","                                                                  STORAGE_ACCOUNT_NAME, \n","                                                                  STORAGE_ACCOUNT_SUFFIX)\n","\n","print(wasbTelemetryUrl)\n","sc = SparkSession.builder.getOrCreate()\n","hc = sc._jsc.hadoopConfiguration()\n","hc.set(\"avro.mapred.ignore.inputs.without.extension\", \"false\")\n","if STORAGE_ACCOUNT_KEY:\n","     hc.set(\"fs.azure.account.key.{}.blob.core.windows.net\".format(STORAGE_ACCOUNT_NAME), STORAGE_ACCOUNT_KEY)\n","hc.set(\"fs.azure.account.key.{}.blob.core.windows.net\"\n","    .format(STORAGE_ACCOUNT_NAME), STORAGE_ACCOUNT_KEY)\n","sql = SQLContext.getOrCreate(sc)\n","avroblob = sql.read.format(\"com.databricks.spark.avro\").load(wasbTelemetryUrl)\n","avroblob.show()"],"outputs":[{"output_type":"stream","name":"stdout","text":["wasb://azureml-blobstore-0ff7b38e-1ad8-4df4-ba02-5135c243b83f@ws1237100807342.blob.core.windows.net/*/*/*/*/*/*/*\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'SparkSession' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-e1d08bc56a11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwasbTelemetryUrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mhc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhadoopConfiguration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mhc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"avro.mapred.ignore.inputs.without.extension\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"false\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'SparkSession' is not defined"]}],"execution_count":6,"metadata":{}},{"cell_type":"markdown","source":["### Convert byteformatted \"body\" of raw blob data into JSON, explode result into new Pyspark DataFrame\n","The output here shows the schema of the telemetry data as well as a preview of the telemetry data with the specific columns necessary for FeatureEngineering and ModelTraining"],"metadata":{}},{"cell_type":"code","source":["#Convert byteformat to string format in pyspark dataframe\n","from json import loads as Loads\n","column = avroblob['Body']\n","string_udf = udf(lambda x: x.decode(\"utf-8\"))\n","avroblob=avroblob.withColumn(\"BodyString\", string_udf(column))\n","avroblob.printSchema()\n","\n","#Convert \"body\" into new DataFrame\n","telemetry_df = sql.read.json(avroblob.select(\"BodyString\").rdd.map(lambda r: r.BodyString))\n","subsetted_df = telemetry_df.select([\"timestamp\", \"ambient_pressure\",\"ambient_temperature\",\"machineID\",\"pressure\",\"speed\",\"speed_desired\",\"temperature\"])\n","subsetted_df.show()"],"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'avroblob' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-7916b9134620>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Convert byteformat to string format in pyspark dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjson\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloads\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mLoads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavroblob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mstring_udf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mavroblob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mavroblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BodyString\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_udf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'avroblob' is not defined"]}],"execution_count":4,"metadata":{}},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["import datetime\n","e = '%Y-%m-%dT%H:%M:%S.%f'\n","reformatted_time_df = subsetted_df.withColumn(\"timestamp\", F.col(\"timestamp\").cast(\"timestamp\"))\n","\n","reformatted_time_df.printSchema()"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":["### Write dataframe to Parquet format"],"metadata":{}},{"cell_type":"code","source":["reformatted_time_df.write.parquet(data_dir+\"/telemetry\", mode=\"overwrite\")"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":["## Get Logs"],"metadata":{}},{"cell_type":"code","source":["#table retrieval\n","table_service = TableService(account_name=STORAGE_ACCOUNT_NAME, account_key=STORAGE_ACCOUNT_KEY)\n","tblob = table_service.query_entities(LOG_TABLE_NAME)"],"outputs":[],"execution_count":13,"metadata":{"gather":{"logged":1598301771448}}},{"cell_type":"markdown","source":["### Process log table data into Pandas DataFrame"],"metadata":{}},{"cell_type":"code","source":["attributes = list()\n","for row in tblob:\n","    if (len(attributes) == 0):\n","        for attribute in row:\n","            attributes.append(attribute)\n","    break\n","log_df = pd.DataFrame(columns=attributes)\n","for row in tblob:\n","    if (row[\"Level\"] != \"DEBUG\"):\n","        row_dict = {}    \n","        for attribute in row:\n","            if (attribute != \"Timestamp\"):\n","                row_dict[attribute] = row[attribute]\n","            else:\n","                newtime = row[attribute].replace(tzinfo=None)\n","                timeitem = pd.Timestamp(newtime, tz=None)\n","                row_dict[attribute] = timeitem\n","        log_df = log_df.append(row_dict, ignore_index=True)\n","log_df.head()"],"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"Empty DataFrame\nColumns: []\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14,"metadata":{"gather":{"logged":1598301774572}}},{"cell_type":"markdown","source":["### Number of Run-To-Failure Sequences\n","The number of Run-To-Failure sequences is especially important for FeatureEngineering and ModelTraining as these log instances are used to train the predictive model. If there are no failure sequences logged, then training a predictive model is useless as the model has no reference for what a situation for failure may look like. Do not proceed with the notebooks if there are no Run-To-Failure sequences logged."],"metadata":{}},{"cell_type":"code","source":["message_counts = log_df['Message'].value_counts()\n","if ('failure' in message_counts):\n","    print(\"Number of Run-to-Failures:\", message_counts['failure'])\n","else:\n","    raise ValueError('Run to failure count is 0. Do not proceed.')"],"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'Message'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Message'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-65f4b470358e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmessage_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'failure'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmessage_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of Run-to-Failures:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'failure'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Run to failure count is 0. Do not proceed.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Message'"]}],"execution_count":15,"metadata":{}},{"cell_type":"markdown","source":["### Select necessary attributes"],"metadata":{}},{"cell_type":"code","source":["log_df = log_df[[\"Timestamp\", \"Code\", \"Level\", \"PartitionKey\"]].astype(str)\n","log_df.columns = [\"timestamp\", \"code\",\"level\",\"machineID\"]\n","log_df.index = log_df['timestamp']\n","log_df.head()"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":["### Write logs to system storage"],"metadata":{}},{"cell_type":"code","source":["log_df = sqlContext.createDataFrame(log_df)\n","log_df.write.parquet(data_dir+\"/logs\", mode=\"overwrite\")"],"outputs":[],"execution_count":null,"metadata":{}}],"metadata":{"kernelspec":{"name":"python3-azureml","language":"python","display_name":"Python 3.6 - AzureML"},"language_info":{"name":"python","version":"3.6.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"nteract":{"version":"nteract-front-end@1.0.0"},"kernel_info":{"name":"python3-azureml"}},"nbformat":4,"nbformat_minor":2}